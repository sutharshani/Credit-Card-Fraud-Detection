{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Term Project</center><br><center>Credit Card Fraud Detection</center>\n",
    "\n",
    "<center><b>Predictive Analytics</b><br>By<br></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><b>Shani Kumar<br> Yalamanchilli ChandraMoulli</b></center>\n",
    "\n",
    "\n",
    "### Introduction:\n",
    "\n",
    "<b>Project Assignment: Credit Card Fraud Detection</b>\n",
    "Increasing fraud in the industry makes fraud prediction very critical to be able to identify and stop fraud in real time, and data science plays a significant role in analyzing and being able to predict fraud based on transactional and cardholder information. The scope of this project is to research and identify different types of predictive analysis algorithms available that can be applied to determine and stop fraudulent transactions.\n",
    "\n",
    "<b>Data source</b> We are using dataset from Kaggle.com - creditcard.csv file.\n",
    "\n",
    "<b>Backgroud of Dataset</b> This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, owner of the dataset did not provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are ‘Time’ and ‘Amount’. Feature ‘Time’ contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature ‘Amount’ is the transaction Amount, this feature can be used for example-dependent cost-sensitive learning. Feature ‘Class’ is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "\n",
    "\n",
    "### Source Data\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "**creditcard.csv** - Transaction Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# configure display of graph\n",
    "%matplotlib inline\n",
    "\n",
    "#stop unnecessary warnings from printing to the screen\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "Class=0, Count=284315, Percentage=99.827%\n",
      "Class=1, Count=492, Percentage=0.173%\n"
     ]
    }
   ],
   "source": [
    "# load the csv file as a data frame\n",
    "trn = pd.read_csv('data/creditcard.csv')\n",
    "# summarize the shape of the dataset\n",
    "print(trn.shape)\n",
    "# summarize the class distribution\n",
    "target = trn.values[:,-1]\n",
    "counter = Counter(target)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%d, Count=%d, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations based on exploratory analysis done in R and Python\n",
    "1. Transaction distribution follows normal distribution which we usually expect. Mostly transaction happens during the day time. Mostly in the morning time after most stores opens and after mostly after noon time. As the day end transaction count start reducing.\n",
    "1. Most of the transactions are low amount transactions (less then 50$) so we can expect most fraud in this range because high amount transactions people do notice easily.\n",
    "1. Fraudulent transactions are very less in count but thats where we want to exploit and identify fraud transaction characterstics so that we can avoid them by recognizing them before approving.\n",
    "1. The class distribution is confirming the severe skew in distribution, with about 99.827 percent of transactions marked as normal and about 0.173 percent marked as fraudulent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split inpit and output features\n",
    "data = trn.values\n",
    "data_X, data_Y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling after oversampling the data using SMOTE method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define resampling method and split into train and test\n",
    "method = SMOTE()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, train_size=0.6, random_state=0)\n",
    "\n",
    "# Apply resampling to the training data only\n",
    "X_resampled, y_resampled = method.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate precision-recall area under curve\n",
    "def pr_auc(y_true, probas_pred):\n",
    "    # calculate precision-recall curve\n",
    "    p, r, _ = precision_recall_curve(y_true, probas_pred)\n",
    "    # calculate area under curve\n",
    "    return auc(r, p)\n",
    " \n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define the model evaluation the metric\n",
    "    metric = make_scorer(pr_auc, needs_proba=True)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "# define models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # DTREE\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    names.append('DTREE')\n",
    "    # KNN\n",
    "    steps = [('s',StandardScaler()),('m',KNeighborsClassifier())]\n",
    "    models.append(Pipeline(steps=steps))\n",
    "    names.append('KNN')\n",
    "    # RF\n",
    "    models.append(RandomForestClassifier(n_estimators=100))\n",
    "    names.append('RF')\n",
    "    # ET\n",
    "    models.append(ExtraTreesClassifier(n_estimators=100))\n",
    "    names.append('ET')\n",
    "    # Bagging\n",
    "    models.append(BaggingClassifier(n_estimators=100))\n",
    "    names.append('BAG')\n",
    "    return models, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">DTREE 0.999 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "models, names = get_models()\n",
    "results = list()\n",
    "\n",
    "i=0\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_resampled, y_resampled, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">KNN 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_resampled, y_resampled, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RF 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_resampled, y_resampled, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ET 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "i=3\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_resampled, y_resampled, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">BAG 1.000 (0.000)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_resampled, y_resampled, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prediction and evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.8911200466120125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    113724\n",
      "         1.0       0.45      0.78      0.57       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.72      0.89      0.79    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113533    191]\n",
      " [    43    156]]\n"
     ]
    }
   ],
   "source": [
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_DT.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_DT.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9041518397092563\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    113724\n",
      "         1.0       0.55      0.80      0.65       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.78      0.90      0.83    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113595    129]\n",
      " [    40    159]]\n"
     ]
    }
   ],
   "source": [
    "# define model to evaluate\n",
    "model = KNeighborsClassifier()\n",
    "# scale, then fit model\n",
    "pipeline = Pipeline(steps=[('s',StandardScaler()), ('m',model)])\n",
    "\n",
    "pipeline.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = pipeline.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.94364532203418\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    113724\n",
      "         1.0       0.75      0.81      0.78       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.87      0.90      0.89    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113669     55]\n",
      " [    38    161]]\n"
     ]
    }
   ],
   "source": [
    "model_BC = BaggingClassifier(n_estimators=100)\n",
    "model_BC.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_BC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_BC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9582566909324153\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    113724\n",
      "         1.0       0.88      0.82      0.85       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.94      0.91      0.92    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113701     23]\n",
      " [    35    164]]\n"
     ]
    }
   ],
   "source": [
    "model_RFC = RandomForestClassifier(n_estimators=100)\n",
    "model_RFC.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_RFC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_RFC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9637868080156683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    113724\n",
      "         1.0       0.90      0.82      0.86       199\n",
      "\n",
      "    accuracy                           1.00    113923\n",
      "   macro avg       0.95      0.91      0.93    113923\n",
      "weighted avg       1.00      1.00      1.00    113923\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113706     18]\n",
      " [    35    164]]\n"
     ]
    }
   ],
   "source": [
    "model_EC = ExtraTreesClassifier(n_estimators=100)\n",
    "model_EC.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_EC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_EC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling without oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">DTREE 0.754 (0.045)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_train, y_train, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">KNN 0.865 (0.047)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_train, y_train, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">RF 0.853 (0.048)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_train, y_train, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ET 0.860 (0.051)\n"
     ]
    }
   ],
   "source": [
    "i=3\n",
    "\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X_train, y_train, models[i])\n",
    "results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skiped this one because it was taking a lot of time to complete\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "\n",
    "# evaluate the model and store results\n",
    "#scores = evaluate_model(X_train, y_train, models[i])\n",
    "#results.append(scores)\n",
    "\n",
    "# summarize performance\n",
    "#print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "print(\"Skiped this one because it was taking a lot of time to complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prediction and evaluate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9057471398465008\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56861\n",
      "         1.0       0.79      0.81      0.80       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56839    22]\n",
      " [   19    82]]\n"
     ]
    }
   ],
   "source": [
    "model_DT = DecisionTreeClassifier()\n",
    "model_DT.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_DT.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_DT.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9256089323956753\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56861\n",
      "         1.0       0.90      0.80      0.85       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56852     9]\n",
      " [   20    81]]\n"
     ]
    }
   ],
   "source": [
    "# define model to evaluate\n",
    "model = KNeighborsClassifier()\n",
    "# scale, then fit model\n",
    "pipeline = Pipeline(steps=[('s',StandardScaler()), ('m',model)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = pipeline.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skiped this one because it was taking a lot of time to complete\n"
     ]
    }
   ],
   "source": [
    "#model_BC = BaggingClassifier(n_estimators=100)\n",
    "#model_BC.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "#predicted = model_BC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "#probs = model_BC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "#print('ROC Score:')\n",
    "#print(roc_auc_score(y_test, probs[:,1]))\n",
    "#print('\\nClassification Report:')\n",
    "#print(classification_report(y_test, predicted))\n",
    "#print('\\nConfusion Matrix:')\n",
    "#print(confusion_matrix(y_test, predicted))\n",
    "print(\"Skiped this one because it was taking a lot of time to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9442533215879403\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56861\n",
      "         1.0       0.94      0.77      0.85       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56856     5]\n",
      " [   23    78]]\n"
     ]
    }
   ],
   "source": [
    "model_RFC = RandomForestClassifier(n_estimators=100)\n",
    "model_RFC.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_RFC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_RFC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score:\n",
      "0.9637172357604378\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56861\n",
      "         1.0       0.94      0.79      0.86       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56856     5]\n",
      " [   21    80]]\n"
     ]
    }
   ],
   "source": [
    "model_EC = ExtraTreesClassifier(n_estimators=100)\n",
    "model_EC.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predictions from our random forest model \n",
    "predicted = model_EC.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model_EC.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print('ROC Score:')\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predicted))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " | Model         | Description | Avg PR-AUC (With Sampling)   | Avg PR-AUC (Without Sampling) \n",
    "| :---           |    :----   |          ---: |          ---: |\n",
    "| Decision Tree Classifier            | Very intuitive and easy to explain but small change in the data can cause a large change in the structure of the decision tree causing instability  | 0.999   | 0.754 |\n",
    "| K Neighbors Classifier    | Easy to implement and understand, but has a major drawback of becoming significantly slows as the size of that data in use grows.        | 1.000      | 0.865 |\n",
    "| Bagging Classifier  | Help reduce variance from models that are might be very accurate, but only on the data they were trained on. Takes a lot of time   | 1.000      | |\n",
    "| Random Forest Classifier | Simple and relatively fast Model. It offers a lot of scope in improving the model’s precision by tuning the hyperparameters and choosing the crucial features.       | 1.000      | 0.853\n",
    "| Extra Tree Classifier | One of the best performing model. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:        | 1.000      | 0.860 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### From Model with Oversample training data\n",
    " \n",
    " | Model         | ROC Score | True Negetive   | False Positive | False Negative | True Positive\n",
    "| :---           |    ----:  |          ---: |          ---: |         ---: |         ---: |\n",
    "| Decision Tree Classifier  |  0.891| 113533   | 191 | 43|156\n",
    "| K Neighbors Classifier    |  0.904| 113595   | 129 | 40|159\n",
    "| Bagging Classifier        |  0.943| 113669   | 55  | 38|161\n",
    "| Random Forest Classifier  |  0.958| 113701   | 23  | 35|164\n",
    "| Extra Tree Classifier     |  0.963| 113706   | 18  | 35|164\n",
    "\n",
    " #### From Model without Oversample training data\n",
    " \n",
    " | Model         | ROC Score | True Negetive   | False Positive | False Negative | True Positive\n",
    "| :---           |    ----:  |          ---: |          ---: |         ---: |         ---: |\n",
    "| Decision Tree Classifier  |  0.905|    56839|  22| 19| 82\n",
    "| K Neighbors Classifier    |  0.925|    56852|  9| 20| 81\n",
    "| Bagging Classifier        |  |    |  | |\n",
    "| Random Forest Classifier  |  0.944|    56856|  5| 23| 78\n",
    "| Extra Tree Classifier     |  0.963|    56856|  5| 21| 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Summary\n",
    "\n",
    "Here are the basis of the selection and feedback based on execution result.\n",
    "\n",
    "**1. Decision Tree Classifier** Decision Tree solves the problem of machine learning by transforming the data into tree representation. requires less effort for data preparation during pre-processing and does not require normalization of data. Missing values in the data also does not affect the process of building decision tree to any considerable extent. It was one of the fast performing model and accuracy was good still it was worst performing model among other based on accuracy.\n",
    "\n",
    "**2. K-Nearest Neighbor classifier**\n",
    "KNN was a good simple model to try because it ‘trains’ very quickly by offsetting most of the computation to the actual testing portion. It is Flexible to feature/distance choices and naturally handles multi-class cases. Additionally it is relatively intuitive how the model works.  It was one of the good performing model.\n",
    "\n",
    "**3. Random Forest classifier**\n",
    "Random forest algorithm can be used for both classifications and regression task. It provides higher accuracy and handles the missing values and maintain the accuracy of a large proportion of data. If there are more trees, it won’t allow overfitting trees in the model and has the power to handle a large data set with higher dimensionality.\n",
    "It was one of the good performing model and also it performed fast as compared to KNN.\n",
    "\n",
    "**4. Bagging Classifier** Bagging takes the advantage of ensemble learning wherein multiple weak learner outperform a single strong learner. It helps reduce variance and thus helps us avoid overfitting. It was taking a lot of time to train the model so I could not execute and get evaluation matric for model without oversampling. \n",
    "\n",
    "**5. Extra Tree Classifier** ExtraTreesClassifier is an ensemble learning method fundamentally based on decision trees. ExtraTreesClassifier, like RandomForest, randomizes certain decisions and subsets of data to minimize over-learning from the data and overfitting. This method has yielded state-of-the-art results in several high-dimensional complex problems. It was best performing model.\n",
    "\n",
    "Extra Tree Classifier works best and also works good with new data. KNN, Random-Forest & Bagging are other models that performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
